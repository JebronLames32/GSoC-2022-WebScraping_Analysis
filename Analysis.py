from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd
from webdriver_manager.chrome import ChromeDriverManager
import requests
import urllib.request
import time
import json

"""
We add the body of the page to a file named body.html

Manually, we open the file and copy the body elements of the page and paste it in the file.(found this easier than getting content from the API)

We use BeautifulSoup to parse the html file and get the links of the organization GSoC pages.
"""
filename="./body.html"
file=open(filename, "r")
body=file.read()
soup = BeautifulSoup(body, "html.parser")

url="https://summerofcode.withgoogle.com/"

"""
We create lists to store the data we want to extract from the page.
The lists are:
name: name of the organization
tools: tech_stack used by the organization
topics: topics of the organization
number_accepted: number of students accepted in an organization

We use the links of the organization GSoC pages to get the data we want."""
name=[] #List to store name of the organization
tools=[] #List to store tech_stack used by the organization
topics=[] #List to store topics of the organization
number_accepted=[] #List to store number of students accepted in an organization
links=[] #List to store links of the organization

count=0
for a in soup.findAll('a', href=True, attrs={'class':'content'}):
    count+=1
    links.append(a['href'])

print(len(links), count)
## Would print the number of organizations and the number of links we got from the page.

"""
This is the template of the python code generated by the website "https://curlconverter.com/".

We use this to get the data we want from the API.

We copy the curl of the request API and use the website to generate this python code.

The params[organization_slug] is the slug of the organization. We change this for each organization. The rest of the template remains the same.
"""
cookies = {
    'G_ENABLED_IDPS': 'google',
    '_ga': 'GA1.3.1625993924.1670530121',
    '_gid': 'GA1.3.1111520402.1671710688',
    '_gat_gtag_UA_53341410_6': '1',
}

headers = {
    'authority': 'summerofcode.withgoogle.com',
    'accept': 'application/json, text/plain, */*',
    'accept-language': 'en-US,en;q=0.9',
    # 'cookie': 'G_ENABLED_IDPS=google; _ga=GA1.3.1625993924.1670530121; _gid=GA1.3.1111520402.1671710688; _gat_gtag_UA_53341410_6=1',
    'referer': 'https://summerofcode.withgoogle.com/programs/2022/organizations/ardupilot',
    'sec-ch-ua': '"Not?A_Brand";v="8", "Chromium";v="108", "Google Chrome";v="108"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"Linux"',
    'sec-fetch-dest': 'empty',
    'sec-fetch-mode': 'cors',
    'sec-fetch-site': 'same-origin',
    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
}

params = {
    'role': '',
    'program_slug': '2022',
    'organization_slug': 'changeThis',
}

"""
Looping through all the links and getting the data we want.
"""
for i in range(len(links)):
    print(links[i])
    params['organization_slug']=links[i].split('/')[4]
    response = requests.get('https://summerofcode.withgoogle.com/api/projects/', params=params, cookies=cookies, headers=headers)
    javascript=response.content
    # print(javascript)
    javascript=javascript.decode("utf-8")
    raw_javascript=r'{}'.format(javascript)
    raw_javascript=raw_javascript.replace('true', 'True')
    raw_javascript=raw_javascript.replace('false', 'False')
    raw_javascript=raw_javascript.replace('null', 'None')
    dict=eval(raw_javascript)
    if(len(dict['entities']['organizations'])>0):
        raw_org_info=r'{}'.format(dict['entities']['organizations'][0])
        raw_org_info=eval(raw_org_info)
        # print(raw_org_info.keys())
        
        name.append(raw_org_info['name'])
        tools.append(raw_org_info['tech_tags'])
        topics.append(raw_org_info['topic_tags'])
    else:
        name.append(links[i].split('/')[4])
        tools.append('None')
        topics.append('None')

    number_accepted.append(len(dict['entities']['projects']))
    
print(len(name), len(tools), len(topics), len(number_accepted))

"""
We create a dataframe and save it as a csv file.
"""
df=pd.DataFrame({'Organization Name':name, 'Tech Stack':tools, 'Topics':topics, 'Number of Students Accepted':number_accepted})
df.to_csv('organizations.csv', index=False, encoding='utf-8')

